{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import platform\n",
    "system_type = platform.system()\n",
    "path = f'../{system_type.lower()}'\n",
    "if system_type == 'Windows':\n",
    "    path = path.replace('/', '\\\\')\n",
    "sys.path.append(path)\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "calibrator = ctypes.CDLL(\"./calibrator.so\")\n",
    "calibrator_acc = ctypes.CDLL(\"./calibrator_acc.so\")\n",
    "evaluator = ctypes.CDLL(\"./evaluator.so\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries \n",
    "from optimizer import *\n",
    "from calibrator import *\n",
    "from evaluator import *\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as rt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ONNX model \n",
    "onnx_model = onnx.load(\"handrecognition_model.onnx\")\n",
    "\n",
    "\n",
    "#optimize ONNX model \n",
    "optimized_model_path = optimize_fp_model(\"handrecognition_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load calibration dataset\n",
    "with open('X_cal.pkl', 'rb') as f:\n",
    "    (test_images) = pickle.load(f)\n",
    "with open('y_cal.pkl', 'rb') as f:\n",
    "    (test_labels) = pickle.load(f)\n",
    "\n",
    "calib_dataset = test_images[0:1800:20]\n",
    "pickle_file_path = 'handrecognition_calib.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calibration \n",
    "model_proto = onnx.load(optimized_model_path)\n",
    "print('Generating the quantization table:')\n",
    "calib = Calibrator('int16', 'per-tensor', 'minmax')\n",
    "\n",
    "\n",
    "###for in8 conversion \n",
    "#calib = Calibrator('int8', 'per-channel', 'minmax') \n",
    "\n",
    "\n",
    "calib.set_providers(['CPUExecutionProvider'])\n",
    "# Obtain the quantization parameter\n",
    "calib.generate_quantization_table(model_proto, calib_dataset, 'handrecognition_calib.pickle')\n",
    "# Generate the coefficient files for esp32s3\n",
    "calib.export_coefficient_to_cpp(model_proto,  pickle_file_path, 'esp32s3', '.', 'handrecognition_coefficient', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the performance on esp32s3:\n",
      "accuracy of int8 model is: 0.923148\n",
      "accuracy of fp32 model is: 0.923148\n"
     ]
    }
   ],
   "source": [
    "    # Evaluate the performance\n",
    "    print('Evaluating the performance on esp32s3:')\n",
    "    eva = Evaluator('int16', 'per-tensor', 'esp32s3')\n",
    "    eva.set_providers(['CPUExecutionProvider'])\n",
    "    eva.generate_quantized_model(model_proto, pickle_file_path)\n",
    "\n",
    "    output_names = [n.name for n in model_proto.graph.output]\n",
    "    providers = ['CPUExecutionProvider']\n",
    "    m = rt.InferenceSession(optimized_model_path, providers=providers)\n",
    "\n",
    "    batch_size = 100\n",
    "    batch_num = int(len(test_images) / batch_size)\n",
    "    res = 0\n",
    "    fp_res = 0\n",
    "    input_name = m.get_inputs()[0].name\n",
    "    for i in range(batch_num):\n",
    "        # int8_model\n",
    "        [outputs, _] = eva.evalute_quantized_model(test_images[i * batch_size:(i + 1) * batch_size], False)\n",
    "        res = res + sum(np.argmax(outputs[0], axis=1) == test_labels[i * batch_size:(i + 1) * batch_size])\n",
    "\n",
    "        # floating-point model\n",
    "        fp_outputs = m.run(output_names, {input_name: test_images[i * batch_size:(i + 1) * batch_size].astype(np.float32)})\n",
    "        fp_res = fp_res + sum(np.argmax(fp_outputs[0], axis=1) == test_labels[i * batch_size:(i + 1) * batch_size])\n",
    "\n",
    "    print('accuracy of int16 model is: %f' % (res / len(test_images)))\n",
    "    print('accuracy of fp32 model is: %f' % (fp_res / len(test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the quantization table:\n",
      "Converting coefficient to int16 per-tensor quantization for esp32s3\n",
      "Exporting finish, the output files are: ./handrecognition_coefficient.cpp, ./handrecognition_coefficient.hpp\n",
      "\n",
      "Quantized model info:\n",
      "model input name: input, exponent: -7\n",
      "Reshape layer name: sequential_1/conv2d_3/BiasAdd__38, output_exponent: -7\n",
      "Conv layer name: sequential_1/conv2d_3/BiasAdd, output_exponent: -8\n",
      "MaxPool layer name: sequential_1/max_pooling2d_3/MaxPool, output_exponent: -8\n",
      "Conv layer name: sequential_1/conv2d_4/BiasAdd, output_exponent: -8\n",
      "MaxPool layer name: sequential_1/max_pooling2d_4/MaxPool, output_exponent: -8\n",
      "Conv layer name: sequential_1/conv2d_5/BiasAdd, output_exponent: -8\n",
      "MaxPool layer name: sequential_1/max_pooling2d_5/MaxPool, output_exponent: -8\n",
      "Transpose layer name: sequential_1/max_pooling2d_5/MaxPool__60, output_exponent: -8\n",
      "Reshape layer name: sequential_1/flatten_1/Reshape, output_exponent: -8\n",
      "Gemm layer name: fused_gemm_0, output_exponent: -8\n",
      "Gemm layer name: fused_gemm_1, output_exponent: -9\n",
      "Softmax layer name: sequential_1/dense_3/Softmax, output_exponent: -14\n",
      "\n",
      "\n",
      "Evaluating the performance on esp32s3 with int8 quantization:\n",
      "Accuracy of int8 model on esp32s3 is: 0.1754\n",
      "Accuracy of fp32 model on esp32s3 is: 0.9917\n",
      "Average inference time per sample of int8 model on esp32s3 is: 1832.519722 us\n",
      "Average inference time per sample of fp32 model on esp32s3 is: 331.163406 us\n",
      "Evaluating the performance on esp32s3 with int16 quantization:\n",
      "Accuracy of int16 model on esp32s3 is: 0.9917\n",
      "Accuracy of fp32 model on esp32s3 is: 0.9917\n",
      "Average inference time per sample of int16 model on esp32s3 is: 1879.157543 us\n",
      "Average inference time per sample of fp32 model on esp32s3 is: 333.009911 us\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import ctypes\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "\n",
    "# Determine the system type and set the path accordingly\n",
    "system_type = platform.system()\n",
    "path = f'../{system_type.lower()}'\n",
    "if system_type == 'Windows':\n",
    "    path = path.replace('/', '\\\\')\n",
    "sys.path.append(path)\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Load the shared libraries\n",
    "calibrator = ctypes.CDLL(\"./calibrator.so\")\n",
    "calibrator_acc = ctypes.CDLL(\"./calibrator_acc.so\")\n",
    "evaluator = ctypes.CDLL(\"./evaluator.so\")\n",
    "\n",
    "# Import custom modules\n",
    "from optimizer import *\n",
    "from calibrator import *\n",
    "from evaluator import *\n",
    "\n",
    "# Load ONNX model\n",
    "onnx_model = onnx.load(\"handrecognition_model.onnx\")\n",
    "\n",
    "# Optimize ONNX model\n",
    "optimized_model_path = optimize_fp_model(\"handrecognition_model.onnx\")\n",
    "\n",
    "# Load calibration dataset\n",
    "with open('X_cal.pkl', 'rb') as f:\n",
    "    calib_images = pickle.load(f)\n",
    "with open('y_cal.pkl', 'rb') as f:\n",
    "    calib_labels = pickle.load(f)\n",
    "\n",
    "# Prepare calibration subset\n",
    "calib_dataset = calib_images[0:1800:20]\n",
    "pickle_file_path = 'handrecognition_calib.pickle'\n",
    "\n",
    "# Calibration\n",
    "model_proto = onnx.load(optimized_model_path)\n",
    "print('Generating the quantization table:')\n",
    "calib = Calibrator('int16', 'per-tensor', 'minmax')\n",
    "calib.set_providers(['CPUExecutionProvider'])\n",
    "calib.generate_quantization_table(model_proto, calib_dataset, 'handrecognition_calib.pickle')\n",
    "calib.export_coefficient_to_cpp(model_proto, pickle_file_path, 'esp32s3', '.', 'handrecognition_coefficient', True)\n",
    "\n",
    "# Load test dataset\n",
    "with open('X_test.pkl', 'rb') as f:\n",
    "    test_images = pickle.load(f)\n",
    "with open('y_test.pkl', 'rb') as f:\n",
    "    test_labels = pickle.load(f)\n",
    "\n",
    "def evaluate_model_on_board(board_name, model_proto, pickle_file_path, test_images, test_labels, quantization_type):\n",
    "    if board_name not in ['esp32s3', 'esp32', 'esp32c3']:\n",
    "        print(f\"Warning: Board {board_name} is not officially supported.\")\n",
    "    else:\n",
    "        print(f'Evaluating the performance on {board_name} with {quantization_type} quantization:')\n",
    "    try:\n",
    "        eva = Evaluator(quantization_type, 'per-tensor', board_name)\n",
    "        eva.set_providers(['CPUExecutionProvider'])\n",
    "        eva.generate_quantized_model(model_proto, pickle_file_path)\n",
    "\n",
    "        output_names = [n.name for n in model_proto.graph.output]\n",
    "        providers = ['CPUExecutionProvider']\n",
    "        m = rt.InferenceSession(optimized_model_path, providers=providers)\n",
    "\n",
    "        batch_size = 100\n",
    "        batch_num = int(len(test_images) / batch_size)\n",
    "        res = 0\n",
    "        fp_res = 0\n",
    "        input_name = m.get_inputs()[0].name\n",
    "\n",
    "        quantized_inference_times = []\n",
    "        fp32_inference_times = []\n",
    "\n",
    "        for i in range(batch_num):\n",
    "            # Measure inference time for quantized model\n",
    "            start_time = time.time()\n",
    "            [outputs, _] = eva.evalute_quantized_model(test_images[i * batch_size:(i + 1) * batch_size], False)\n",
    "            end_time = time.time()\n",
    "            quantized_inference_times.append(end_time - start_time)\n",
    "            res = res + sum(np.argmax(outputs[0], axis=1) == test_labels[i * batch_size:(i + 1) * batch_size])\n",
    "\n",
    "            # Measure inference time for floating-point model\n",
    "            start_time = time.time()\n",
    "            fp_outputs = m.run(output_names, {input_name: test_images[i * batch_size:(i + 1) * batch_size].astype(np.float32)})\n",
    "            end_time = time.time()\n",
    "            fp32_inference_times.append(end_time - start_time)\n",
    "            fp_res = fp_res + sum(np.argmax(fp_outputs[0], axis=1) == test_labels[i * batch_size:(i + 1) * batch_size])\n",
    "\n",
    "        # Calculate average inference times per sample\n",
    "        avg_quantized_inference_time = 1000000*((sum(quantized_inference_times) / len(quantized_inference_times)) / batch_size)\n",
    "        avg_fp32_inference_time = 1000000*((sum(fp32_inference_times) / len(fp32_inference_times)) / batch_size)\n",
    "\n",
    "        print(f'Accuracy of {quantization_type} model on {board_name} is: {res / len(test_images):.4f}')\n",
    "        print(f'Accuracy of fp32 model on {board_name} is: {fp_res / len(test_images):.4f}')\n",
    "        print(f'Average inference time per sample of {quantization_type} model on {board_name} is: {avg_quantized_inference_time:.6f} us')\n",
    "        print(f'Average inference time per sample of fp32 model on {board_name} is: {avg_fp32_inference_time:.6f} us')\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error evaluating on {board_name}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify supported boards\n",
    "    esp32_boards = ['esp32s3']\n",
    "    quantization_types = ['int8', 'int16']\n",
    "\n",
    "    for board in esp32_boards:\n",
    "        for quant_type in quantization_types:\n",
    "            evaluate_model_on_board(board, model_proto, pickle_file_path, test_images, test_labels, quant_type)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esp_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
